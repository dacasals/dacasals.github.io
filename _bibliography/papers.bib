---
---

@string{aps = {American Physical Society,}}

@INPROCEEDINGS{9639899,
  author={Amat, Daniel Arturo Casal and Buil-Aranda, Carlos and Valle-Vidal, Carlos},
  booktitle={2021 XLVII Latin American Computing Conference (CLEI)}, 
  title={A Neural Networks Approach to SPARQL Query Performance Prediction}, 
  year={2021},
  volume={},
  number={},
  pages={1-9},
  keywords={Training;Query processing;Neural networks;Estimation;Feature extraction;Data models;Resource description framework;neural networks;query;sparql;latency},
  doi={10.1109/CLEI53233.2021.9639899}}

 @misc{Casals Amat_2021, title={Predicción de rendimiento en consultas SPARQL con Deep Neural networks}, url={https://hdl.handle.net/11673/56382}, abstractNote={Las tecnologías de las Web Semántica están cambiando las formas en la que se comparte la
información, sustituyendo los grandes volúmenes de información en formato HTML por
datasets en los que el dato en bruto es tratado como un “ciudadano de primera clase”. Este
nuevo enfoque busca persuadir a las organizaciones, empresas e individuos a que publiquen
sus datos libremente siguiendo los estándares propuestos por la W3C y enlazando diferentes
áreas del conocimiento generando la llamada Web de los Datos Enlazados. El público
objetivo para consumir estos datos incluye tanto personas como aplicaciones de software.
En los últimos años, la aplicaciones de software han incrementado las capacidades
de extraer información útil de estos grandes volúmenes de datos estructurados utilizando
lenguajes como SPARQL que es el estándar para consultar datos RDF y se ha implementado
en una amplia variedad de motores. Estos motores brindan el acceso a los datos a través
de endpoints públicos en la Web, los cuales reciben miles de consultas diariamente. En
muchos casos, estos endpoints enfrentan dificultades al evaluar consultas complejas o
cuando reciben demasiadas al mismo tiempo. Esto provoca que los tiempos de respuesta
percibidos por los clientes que ejecutan las consultas se vean afectados, sobre todo porque
algunas de estas consultas necesitan grandes cantidades de recursos para ser procesadas.
Todos estos motores tienen un optimizador de consultas interno que propone un plan de
ejecución de consultas supuestamente óptimo, sin embargo, esta es una tarea difícil ya que
puede haber miles de posibles planes de consulta a considerar y el optimizador puede no
elegir el mejor.
En dependencia de los recursos computacionales disponibles es posible implementar
también arquitecturas más complejas como réplicas y balances de carga, o incluso nuevos
conceptos “Self-Driving Database Management Systems”.
Sin embargo, todos estos mecanismos dependen de buenos estimadores de la latencia
de ejecución de las consultas. Hasta donde sabemos, en general, los estimadores de latencia
para consultas SPARQL se basan en heurísticas sobre información estadística de las
bases de datos. Otros técnicas como el uso de Support Vector Machine han mejorado las
predicciones.
En esta propuesta se utilizan redes neuronales profundas para la creación de un estimador
de latencias de consultas SPARQL que supera los resultados obtenidos en técnicas
anteriores y que puede servir como base de apoyo para la construcción de técnicas de optimización más avanzadas.
El estimador fue evaluado en bases de datos sintéticas y reales. Los resultados muestran
que el desempeño de redes neuronales profundas supera las propuestas anteriores en el
contexto de la predicción de latencia en consultas SPARQL.}, author={Casals Amat, Daniel Arturo}, year={2021}, month={Mar}}